{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from data_tools import *\n",
    "from algorithms import *\n",
    "from plot_lib import *\n",
    "from nets import *\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import KFold\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import log_loss\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training and test data\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "path_train_data = \"/Volumes/MoritzBertholdHD/CellData/Experiments/Ex1/PreparedData/all_channels_80_80_full_no_zeros_in_cells.npy\"\n",
    "path_train_labels = \"/Volumes/MoritzBertholdHD/CellData/Experiments/Ex1/PreparedData/labels_80_80_full_no_zeros_in_cells.npy\"\n",
    "path_test_data = \"/Volumes/MoritzBertholdHD/CellData/Experiments/Ex2/PreparedData/all_channels_80_80_full_no_zeros_in_cells.npy\"\n",
    "path_test_labels = \"/Volumes/MoritzBertholdHD/CellData/Experiments/Ex2/PreparedData/labels_80_80_full_no_zeros_in_cells.npy\"\n",
    "\n",
    "print \"Loading training and test data\"\n",
    "X_train = np.array(loadnumpy(path_train_data), dtype = np.uint8).astype('float32')\n",
    "y_train = np.load(path_train_labels)[:,0]\n",
    "X_test = np.array(loadnumpy(path_test_data), dtype = np.uint8).astype('float32')\n",
    "y_test = np.load(path_test_labels)[:,0]\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing the last class for comparison with cell profiler\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Remove class 5 from Data:\n",
    "print \"Removing the last class for comparison with cell profiler\"\n",
    "X_train = X_train[y_train!=4, :]\n",
    "y_train = y_train[y_train!=4]\n",
    "X_test = X_test[y_test!=4, :]\n",
    "y_test = y_test[y_test!=4]\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing data per channel\n",
      "------------ Check Data -------------\n",
      "Trainingdata shape =  (24191, 4, 80, 80)\n",
      "Traininglabels shape =  (24191,)\n",
      "Testdata shape =  (31667, 4, 80, 80)\n",
      "Testlabels shape =  (31667,)\n",
      "Max val:  1.0\n",
      "Max val:  1.0\n",
      "Max val:  1.0\n",
      "Max val:  1.0\n",
      "Max val:  1.0\n",
      "Max val:  1.0\n",
      "Max val:  1.0\n",
      "Max val:  1.0\n",
      "-------------------------------------\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print \"Normalizing data per channel\"\n",
    "max_ch1 = float(np.max(X_train[:, 0, : , :]))\n",
    "max_ch2 = float(np.max(X_train[:, 1, : , :]))\n",
    "max_ch3 = float(np.max(X_train[:, 2, : , :]))\n",
    "max_ch4 = float(np.max(X_train[:, 3, : , :]))\n",
    "X_train[:, 0, : , :] /= max_ch1\n",
    "X_train[:, 1, : , :] /= max_ch2\n",
    "X_train[:, 2, : , :] /= max_ch3\n",
    "X_train[:, 3, : , :] /= max_ch4\n",
    "X_test[:, 0, : , :] /= max_ch1\n",
    "X_test[:, 1, : , :] /= max_ch2\n",
    "X_test[:, 2, : , :] /= max_ch3\n",
    "X_test[:, 3, : , :] /= max_ch4\n",
    "print \"------------ Check Data -------------\"\n",
    "print \"Trainingdata shape = \", X_train.shape\n",
    "print \"Traininglabels shape = \", y_train.shape\n",
    "print \"Testdata shape = \", X_test.shape\n",
    "print \"Testlabels shape = \", y_test.shape\n",
    "print \"Max val: \", np.max(X_train[:,0,:,:])\n",
    "print \"Max val: \", np.max(X_train[:,1,:,:])\n",
    "print \"Max val: \", np.max(X_train[:,2,:,:])\n",
    "print \"Max val: \", np.max(X_train[:,3,:,:])\n",
    "print \"Max val: \", np.max(X_test[:,0,:,:])\n",
    "print \"Max val: \", np.max(X_test[:,1,:,:])\n",
    "print \"Max val: \", np.max(X_test[:,2,:,:])\n",
    "print \"Max val: \", np.max(X_test[:,3,:,:])\n",
    "print \"-------------------------------------\"\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping data for convNet\n",
      "done\n",
      "Training shape (24191, 80, 80, 4)\n",
      "Test shape (31667, 80, 80, 4)\n"
     ]
    }
   ],
   "source": [
    "print \"Reshaping data for convNet\"\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[3], X_train.shape[2], X_train.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[3], X_test.shape[2], X_test.shape[1])\n",
    "print \"done\"\n",
    "print \"Training shape\", X_train.shape\n",
    "print \"Test shape\", X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def merge_several_folds_mean(data, nfolds):\n",
    "    a = np.array(data[0])\n",
    "    for i in range(1, nfolds):\n",
    "        a += np.array(data[i])\n",
    "    a /= nfolds\n",
    "    return a\n",
    "\n",
    "def get_validation_predictions(train_data, predictions_valid):\n",
    "    pv = []\n",
    "    for i in range(len(train_data)):\n",
    "        pv.append(predictions_valid[i])\n",
    "    return pv\n",
    "\n",
    "def run_cross_validation_create_models(nfolds, X_train, X_test, y_train):\n",
    "    # input image dimensions\n",
    "    batch_size = 8\n",
    "    nb_epoch = 1\n",
    "    random_state = 51\n",
    "\n",
    "    train_data = X_train\n",
    "    train_target = y_train\n",
    "\n",
    "    yfull_train = dict()\n",
    "    kf = KFold(len(y_train), n_folds=nfolds, shuffle=True, random_state=random_state)\n",
    "    num_fold = 0\n",
    "    sum_score = 0\n",
    "    accuracies = 0\n",
    "    models = []\n",
    "    for train_index, test_index in kf:\n",
    "        model = covNetSimple()\n",
    "        X_train = train_data[train_index]\n",
    "        Y_train = train_target[train_index]\n",
    "        X_valid = train_data[test_index]\n",
    "        Y_valid = train_target[test_index]\n",
    "\n",
    "        num_fold += 1\n",
    "        print('Start KFold number {} from {}'.format(num_fold, nfolds))\n",
    "        print('Split train: ', len(X_train), len(Y_train))\n",
    "        print('Split valid: ', len(X_valid), len(Y_valid))\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=5, verbose=0),\n",
    "        ]\n",
    "        model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, shuffle=True, verbose=2, validation_data=(X_valid, Y_valid), callbacks=callbacks)\n",
    "\n",
    "        predictions_valid = model.predict(X_valid.astype('float32'), batch_size=batch_size, verbose=2)\n",
    "        score = log_loss(Y_valid, predictions_valid)\n",
    "        print('Score log_loss: ', score)\n",
    "        sum_score += score*len(test_index)\n",
    "\n",
    "        # Store valid predictions\n",
    "        for i in range(len(test_index)):\n",
    "            yfull_train[test_index[i]] = predictions_valid[i]\n",
    "\n",
    "        test_prediction = model.predict(X_valid.astype('float32'), batch_size=batch_size, verbose=2)\n",
    "        y_pred = np.zeros([test_prediction.shape[0]])\n",
    "        for i in xrange(test_prediction.shape[0]):\n",
    "            y_pred[i] = np.argmax(test_prediction[i,:]).astype(int)\n",
    "        class_names = [\"0\", \"1\", \"2\", \"3\"]\n",
    "        plotNiceConfusionMatrix(Y_valid.astype(int), y_pred.astype(int), class_names)\n",
    "        scores = model.evaluate(X_valid.astype('float32'), Y_valid, verbose=0)\n",
    "        accuracy = accuracy(X_valid.astype('float32'), y_pred.astype(int))\n",
    "        print \"Accuracy is: \", accuracy\n",
    "        accuracies += accuracy\n",
    "\n",
    "\n",
    "        models.append(model)\n",
    "\n",
    "    score = sum_score/len(train_data)\n",
    "    print(\"Log_loss train independent avg: \", score)\n",
    "\n",
    "    print \"no accuracy evaluation!\"\n",
    "    final_accuracy = accuracies / nfolds\n",
    "    print \"Accuracy train independent avg in percent: \", final_accuracy\n",
    "\n",
    "    info_string = 'loss_' + str(score) + '_folds_' + str(nfolds) + '_ep_' + str(nb_epoch)\n",
    "    return info_string, models\n",
    "\n",
    "def process_test_with_cross_val(info_string, models, X_test):\n",
    "    batch_size = 16\n",
    "    num_fold = 0\n",
    "    yfull_test = []\n",
    "    test_id = []\n",
    "    nfolds = len(models)\n",
    "\n",
    "    for i in range(nfolds):\n",
    "        model = models[i]\n",
    "        num_fold += 1\n",
    "        print('Start KFold number {} from {}'.format(num_fold, nfolds))\n",
    "        test_data = X_test\n",
    "        test_prediction = model.predict(test_data, batch_size=batch_size, verbose=2)\n",
    "        yfull_test.append(test_prediction)\n",
    "\n",
    "    test_res = merge_several_folds_mean(yfull_test, nfolds)\n",
    "    info_string = 'loss_' + info_string \\\n",
    "                + '_folds_' + str(nfolds)\n",
    "\n",
    "    print \"Result on test data done: \", test_res.shape\n",
    "    return test_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with num_folds =  3\n",
      "Start KFold number 1 from 3\n",
      "('Split train: ', 16127, 16127)\n",
      "('Split valid: ', 8064, 8064)\n",
      "Train on 16127 samples, validate on 8064 samples\n",
      "Epoch 1/1\n",
      "333s - loss: 0.6989 - val_loss: 0.5183\n",
      "('Score log_loss: ', 0.51827048437658596)\n",
      "The confusion matrix (Truth X Prediction):\n",
      "[[  0.00000000e+00   0.00000000e+00   1.00000000e+00   2.00000000e+00\n",
      "    3.00000000e+00]\n",
      " [  0.00000000e+00   4.94000000e+02   0.00000000e+00   6.08000000e+02\n",
      "    2.30000000e+01]\n",
      " [  1.00000000e+00   3.20000000e+01   0.00000000e+00   5.70000000e+01\n",
      "    4.23000000e+02]\n",
      " [  2.00000000e+00   2.25000000e+02   0.00000000e+00   2.48700000e+03\n",
      "    5.40000000e+01]\n",
      " [  3.00000000e+00   2.90000000e+01   0.00000000e+00   3.28000000e+02\n",
      "    3.30400000e+03]]\n",
      "---------------------------------------------------\t\n",
      "Start KFold number 2 from 3\n",
      "('Split train: ', 16127, 16127)\n",
      "('Split valid: ', 8064, 8064)\n",
      "Train on 16127 samples, validate on 8064 samples\n",
      "Epoch 1/1\n",
      "371s - loss: 0.7156 - val_loss: 0.5515\n",
      "('Score log_loss: ', 0.55153648901019037)\n",
      "The confusion matrix (Truth X Prediction):\n",
      "[[  0.00000000e+00   0.00000000e+00   1.00000000e+00   2.00000000e+00\n",
      "    3.00000000e+00]\n",
      " [  0.00000000e+00   1.77000000e+02   0.00000000e+00   9.06000000e+02\n",
      "    7.40000000e+01]\n",
      " [  1.00000000e+00   6.00000000e+00   0.00000000e+00   7.00000000e+01\n",
      "    3.87000000e+02]\n",
      " [  2.00000000e+00   3.60000000e+01   0.00000000e+00   2.54700000e+03\n",
      "    1.45000000e+02]\n",
      " [  3.00000000e+00   6.00000000e+00   0.00000000e+00   3.06000000e+02\n",
      "    3.40400000e+03]]\n",
      "---------------------------------------------------\t\n",
      "Start KFold number 3 from 3\n",
      "('Split train: ', 16128, 16128)\n",
      "('Split valid: ', 8063, 8063)\n",
      "Train on 16128 samples, validate on 8063 samples\n",
      "Epoch 1/1\n",
      "340s - loss: 0.7486 - val_loss: 0.5418\n",
      "('Score log_loss: ', 0.54181354945850524)\n",
      "The confusion matrix (Truth X Prediction):\n",
      "[[  0.00000000e+00   0.00000000e+00   1.00000000e+00   2.00000000e+00\n",
      "    3.00000000e+00]\n",
      " [  0.00000000e+00   8.90000000e+01   0.00000000e+00   8.70000000e+02\n",
      "    1.35000000e+02]\n",
      " [  1.00000000e+00   5.00000000e+00   0.00000000e+00   3.90000000e+01\n",
      "    4.14000000e+02]\n",
      " [  2.00000000e+00   1.50000000e+01   0.00000000e+00   2.52300000e+03\n",
      "    2.38000000e+02]\n",
      " [  3.00000000e+00   1.00000000e+00   0.00000000e+00   1.96000000e+02\n",
      "    3.53800000e+03]]\n",
      "---------------------------------------------------\t\n",
      "('Log_loss train independent avg: ', 0.53720665051775007)\n",
      "no accuracy evaluation!\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "num_folds = 3\n",
    "print \"Training model with num_folds = \", num_folds\n",
    "info_string, models = run_cross_validation_create_models(num_folds, X_train, X_test, y_train)\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start KFold number 1 from 3\n"
     ]
    }
   ],
   "source": [
    "prediction = process_test_with_cross_val(info_string, models, X_test)\n",
    "print prediction.shapecliq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(prediction).astype(int)\n",
    "print y_pred.shape\n",
    "print \"The final accuracy on test data is \" + str(accuracy(y_pred, y_test)) + \"%.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
