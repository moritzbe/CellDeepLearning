{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/moritzberthold/anaconda2/envs/tensorflow/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from data_tools import *\n",
    "from algorithms import *\n",
    "from plot_lib import *\n",
    "from nets import *\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import KFold\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import log_loss\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training and test data\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "path_train_data = \"/Volumes/MoritzBertholdHD/CellData/Experiments/Ex1/PreparedData/all_channels_80_80_full_no_zeros_in_cells.npy\"\n",
    "path_train_labels = \"/Volumes/MoritzBertholdHD/CellData/Experiments/Ex1/PreparedData/labels_80_80_full_no_zeros_in_cells.npy\"\n",
    "path_test_data = \"/Volumes/MoritzBertholdHD/CellData/Experiments/Ex2/PreparedData/all_channels_80_80_full_no_zeros_in_cells.npy\"\n",
    "path_test_labels = \"/Volumes/MoritzBertholdHD/CellData/Experiments/Ex2/PreparedData/labels_80_80_full_no_zeros_in_cells.npy\"\n",
    "\n",
    "print \"Loading training and test data\"\n",
    "X_train = np.array(loadnumpy(path_train_data), dtype = np.uint8).astype('float32')\n",
    "y_train = np.load(path_train_labels)[:,0]\n",
    "X_test = np.array(loadnumpy(path_test_data), dtype = np.uint8).astype('float32')\n",
    "y_test = np.load(path_test_labels)[:,0]\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove class 5 from Data:\n",
    "print \"Removing the last class for comparison with cell profiler\"\n",
    "X_train = X_train[y_train!=4, :]\n",
    "y_train = y_train[y_train!=4]\n",
    "X_test = X_test[y_test!=4, :]\n",
    "y_test = y_test[y_test!=4]\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing data per channel\n",
      "------------ Check Data -------------\n",
      "Trainingdata shape =  (24191, 4, 80, 80)\n",
      "Traininglabels shape =  (24191,)\n",
      "Testdata shape =  (31667, 4, 80, 80)\n",
      "Testlabels shape =  (31667,)\n",
      "Max val:  1.0\n",
      "Max val:  1.0\n",
      "Max val:  1.0\n",
      "Max val:  1.0\n",
      "Max val:  1.0\n",
      "Max val:  1.0\n",
      "Max val:  1.0\n",
      "Max val:  1.0\n",
      "-------------------------------------\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print \"Normalizing data per channel\"\n",
    "max_ch1 = float(np.max(X_train[:, 0, : , :]))\n",
    "max_ch2 = float(np.max(X_train[:, 1, : , :]))\n",
    "max_ch3 = float(np.max(X_train[:, 2, : , :]))\n",
    "max_ch4 = float(np.max(X_train[:, 3, : , :]))\n",
    "X_train[:, 0, : , :] /= max_ch1\n",
    "X_train[:, 1, : , :] /= max_ch2\n",
    "X_train[:, 2, : , :] /= max_ch3\n",
    "X_train[:, 3, : , :] /= max_ch4\n",
    "X_test[:, 0, : , :] /= max_ch1\n",
    "X_test[:, 1, : , :] /= max_ch2\n",
    "X_test[:, 2, : , :] /= max_ch3\n",
    "X_test[:, 3, : , :] /= max_ch4\n",
    "print \"------------ Check Data -------------\"\n",
    "print \"Trainingdata shape = \", X_train.shape\n",
    "print \"Traininglabels shape = \", y_train.shape\n",
    "print \"Testdata shape = \", X_test.shape\n",
    "print \"Testlabels shape = \", y_test.shape\n",
    "print \"Max val: \", np.max(X_train[:,0,:,:])\n",
    "print \"Max val: \", np.max(X_train[:,1,:,:])\n",
    "print \"Max val: \", np.max(X_train[:,2,:,:])\n",
    "print \"Max val: \", np.max(X_train[:,3,:,:])\n",
    "print \"Max val: \", np.max(X_test[:,0,:,:])\n",
    "print \"Max val: \", np.max(X_test[:,1,:,:])\n",
    "print \"Max val: \", np.max(X_test[:,2,:,:])\n",
    "print \"Max val: \", np.max(X_test[:,3,:,:])\n",
    "print \"-------------------------------------\"\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping data for convNet\n",
      "done\n",
      "Training shape (24191, 80, 80, 4)\n",
      "Test shape (31667, 80, 80, 4)\n"
     ]
    }
   ],
   "source": [
    "print \"Reshaping data for convNet\"\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[3], X_train.shape[2], X_train.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[3], X_test.shape[2], X_test.shape[1])\n",
    "print \"done\"\n",
    "print \"Training shape\", X_train.shape\n",
    "print \"Test shape\", X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def merge_several_folds_mean(data, nfolds):\n",
    "    a = np.array(data[0])\n",
    "    for i in range(1, nfolds):\n",
    "        a += np.array(data[i])\n",
    "    a /= nfolds\n",
    "    return a\n",
    "\n",
    "def get_validation_predictions(train_data, predictions_valid):\n",
    "    pv = []\n",
    "    for i in range(len(train_data)):\n",
    "        pv.append(predictions_valid[i])\n",
    "    return pv\n",
    "\n",
    "def run_cross_validation_create_models(nfolds, X_train, X_test, y_train):\n",
    "    # input image dimensions\n",
    "    batch_size = 8\n",
    "    nb_epoch = 1\n",
    "    random_state = 51\n",
    "\n",
    "    train_data = X_train\n",
    "    train_target = y_train\n",
    "\n",
    "    yfull_train = dict()\n",
    "    kf = KFold(len(y_train), n_folds=nfolds, shuffle=True, random_state=random_state)\n",
    "    num_fold = 0\n",
    "    sum_score = 0\n",
    "    accuracies = 0\n",
    "    models = []\n",
    "    for train_index, test_index in kf:\n",
    "        model = covNetSimple()\n",
    "        X_train = train_data[train_index]\n",
    "        Y_train = train_target[train_index]\n",
    "        X_valid = train_data[test_index]\n",
    "        Y_valid = train_target[test_index]\n",
    "\n",
    "        num_fold += 1\n",
    "        print('Start KFold number {} from {}'.format(num_fold, nfolds))\n",
    "        print('Split train: ', len(X_train), len(Y_train))\n",
    "        print('Split valid: ', len(X_valid), len(Y_valid))\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=5, verbose=0),\n",
    "        ]\n",
    "        model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, shuffle=True, verbose=2, validation_data=(X_valid, Y_valid), callbacks=callbacks)\n",
    "\n",
    "        predictions_valid = model.predict(X_valid.astype('float32'), batch_size=batch_size, verbose=2)\n",
    "        score = log_loss(Y_valid, predictions_valid)\n",
    "        print('Score log_loss: ', score)\n",
    "        sum_score += score*len(test_index)\n",
    "\n",
    "        # Store valid predictions\n",
    "        for i in range(len(test_index)):\n",
    "            yfull_train[test_index[i]] = predictions_valid[i]\n",
    "\n",
    "        test_prediction = model.predict(X_valid.astype('float32'), batch_size=batch_size, verbose=2)\n",
    "        y_pred = np.zeros([test_prediction.shape[0]])\n",
    "        for i in xrange(test_prediction.shape[0]):\n",
    "            y_pred[i] = np.argmax(test_prediction[i,:]).astype(int)\n",
    "        class_names = [\"0\", \"1\", \"2\", \"3\"]\n",
    "        plotNiceConfusionMatrix(Y_valid.astype(int), y_pred.astype(int), class_names)\n",
    "        scores = model.evaluate(X_valid.astype('float32'), Y_valid, verbose=0)\n",
    "        accuracy = accuracy(X_valid.astype('float32'), y_pred.astype(int))\n",
    "        print \"Accuracy is: \", accuracy\n",
    "        accuracies += accuracy\n",
    "\n",
    "\n",
    "        models.append(model)\n",
    "\n",
    "    score = sum_score/len(train_data)\n",
    "    print(\"Log_loss train independent avg: \", score)\n",
    "\n",
    "    print \"no accuracy evaluation!\"\n",
    "    final_accuracy = accuracies / nfolds\n",
    "    print \"Accuracy train independent avg in percent: \", final_accuracy\n",
    "\n",
    "    info_string = 'loss_' + str(score) + '_folds_' + str(nfolds) + '_ep_' + str(nb_epoch)\n",
    "    return info_string, models\n",
    "\n",
    "def process_test_with_cross_val(info_string, models, X_test):\n",
    "    batch_size = 16\n",
    "    num_fold = 0\n",
    "    yfull_test = []\n",
    "    test_id = []\n",
    "    nfolds = len(models)\n",
    "\n",
    "    for i in range(nfolds):\n",
    "        model = models[i]\n",
    "        num_fold += 1\n",
    "        print('Start KFold number {} from {}'.format(num_fold, nfolds))\n",
    "        test_data = X_test\n",
    "        test_prediction = model.predict(test_data, batch_size=batch_size, verbose=2)\n",
    "        yfull_test.append(test_prediction)\n",
    "\n",
    "    test_res = merge_several_folds_mean(yfull_test, nfolds)\n",
    "    info_string = 'loss_' + info_string \\\n",
    "                + '_folds_' + str(nfolds)\n",
    "\n",
    "    print \"Result on test data done: \", test_res.shape\n",
    "    return test_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with num_folds =  4\n",
      "Start KFold number 1 from 4\n",
      "('Split train: ', 18143, 18143)\n",
      "('Split valid: ', 6048, 6048)\n",
      "Train on 18143 samples, validate on 6048 samples\n",
      "Epoch 1/12\n"
     ]
    }
   ],
   "source": [
    "num_folds = 4\n",
    "print \"Training model with num_folds = \", num_folds\n",
    "info_string, models = run_cross_validation_create_models(num_folds, X_train, X_test, y_train)\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start KFold number 1 from 3\n",
      "Start KFold number 2 from 3\n",
      "Start KFold number 3 from 3\n",
      "Result on test data done:  (31667, 4)\n",
      "(31667, 4)\n"
     ]
    }
   ],
   "source": [
    "prediction = process_test_with_cross_val(info_string, models, X_test)\n",
    "print prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31667,)\n",
      "The final accuracy on test data is 78.21%.\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(prediction, axis=1)\n",
    "print y_pred.shape\n",
    "print \"The final accuracy on test data is \" + str(accuracy(y_pred, y_test)) + \"%.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
