{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from data_tools import *\n",
    "from algorithms import *\n",
    "from plot_lib import *\n",
    "from nets import *\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import KFold\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import log_loss\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training and test data\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "path_train_data = \"/Volumes/MoritzBertholdHD/CellData/Experiments/Ex1/PreparedData/all_channels_80_80_full_no_zeros_in_cells.npy\"\n",
    "path_train_labels = \"/Volumes/MoritzBertholdHD/CellData/Experiments/Ex1/PreparedData/labels_80_80_full_no_zeros_in_cells.npy\"\n",
    "path_test_data = \"/Volumes/MoritzBertholdHD/CellData/Experiments/Ex2/PreparedData/all_channels_80_80_full_no_zeros_in_cells.npy\"\n",
    "path_test_labels = \"/Volumes/MoritzBertholdHD/CellData/Experiments/Ex2/PreparedData/labels_80_80_full_no_zeros_in_cells.npy\"\n",
    "\n",
    "print \"Loading training and test data\"\n",
    "X_train = np.array(loadnumpy(path_train_data), dtype = np.uint8).astype('float32')[:,:,::2,::2]\n",
    "y_train = np.load(path_train_labels)[:,0]\n",
    "X_test = np.array(loadnumpy(path_test_data), dtype = np.uint8).astype('float32')[:,:,::2,::2]\n",
    "y_test = np.load(path_test_labels)[:,0]\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing the last class for comparison with cell profiler\n",
      "Distribution train classes (array([0, 1, 2, 3]), array([ 3376,  1433,  8270, 11112]))\n",
      "Distribution test classes (array([0, 1, 2, 3]), array([ 4137,  1833, 11191, 14506]))\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Remove class 5 from Data:\n",
    "print \"Removing the last class for comparison with cell profiler\"\n",
    "X_train = X_train[y_train!=4, :]\n",
    "y_train = y_train[y_train!=4]\n",
    "X_test = X_test[y_test!=4, :]\n",
    "y_test = y_test[y_test!=4]\n",
    "print \"Distribution train classes\", np.unique(y_train, return_counts=True)\n",
    "print \"Distribution test classes\", np.unique(y_test, return_counts=True)\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing data per channel\n",
      "------------ Check Data -------------\n",
      "Trainingdata shape =  (24191, 4, 40, 40)\n",
      "Traininglabels shape =  (24191,)\n",
      "Testdata shape =  (31667, 4, 40, 40)\n",
      "Testlabels shape =  (31667,)\n",
      "Max val:  1.0\n",
      "Max val:  1.0\n",
      "Max val:  1.0\n",
      "Max val:  1.0\n",
      "Max val:  1.0\n",
      "Max val:  1.0\n",
      "Max val:  1.0\n",
      "Max val:  1.0\n",
      "-------------------------------------\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print \"Normalizing data per channel\"\n",
    "max_ch1 = float(np.max(X_train[:, 0, : , :]))\n",
    "max_ch2 = float(np.max(X_train[:, 1, : , :]))\n",
    "max_ch3 = float(np.max(X_train[:, 2, : , :]))\n",
    "max_ch4 = float(np.max(X_train[:, 3, : , :]))\n",
    "X_train[:, 0, : , :] /= max_ch1\n",
    "X_train[:, 1, : , :] /= max_ch2\n",
    "X_train[:, 2, : , :] /= max_ch3\n",
    "X_train[:, 3, : , :] /= max_ch4\n",
    "X_test[:, 0, : , :] /= max_ch1\n",
    "X_test[:, 1, : , :] /= max_ch2\n",
    "X_test[:, 2, : , :] /= max_ch3\n",
    "X_test[:, 3, : , :] /= max_ch4\n",
    "print \"------------ Check Data -------------\"\n",
    "print \"Trainingdata shape = \", X_train.shape\n",
    "print \"Traininglabels shape = \", y_train.shape\n",
    "print \"Testdata shape = \", X_test.shape\n",
    "print \"Testlabels shape = \", y_test.shape\n",
    "print \"Max val: \", np.max(X_train[:,0,:,:])\n",
    "print \"Max val: \", np.max(X_train[:,1,:,:])\n",
    "print \"Max val: \", np.max(X_train[:,2,:,:])\n",
    "print \"Max val: \", np.max(X_train[:,3,:,:])\n",
    "print \"Max val: \", np.max(X_test[:,0,:,:])\n",
    "print \"Max val: \", np.max(X_test[:,1,:,:])\n",
    "print \"Max val: \", np.max(X_test[:,2,:,:])\n",
    "print \"Max val: \", np.max(X_test[:,3,:,:])\n",
    "print \"-------------------------------------\"\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping data for convNet\n",
      "done\n",
      "Training shape (24191, 40, 40, 4)\n",
      "Test shape (31667, 40, 40, 4)\n"
     ]
    }
   ],
   "source": [
    "print \"Reshaping data for convNet\"\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[3], X_train.shape[2], X_train.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[3], X_test.shape[2], X_test.shape[1])\n",
    "print \"done\"\n",
    "print \"Training shape\", X_train.shape\n",
    "print \"Test shape\", X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def merge_several_folds_mean(data, nfolds):\n",
    "    a = np.array(data[0])\n",
    "    for i in range(1, nfolds):\n",
    "        a += np.array(data[i])\n",
    "    a /= nfolds\n",
    "    return a\n",
    "\n",
    "def get_validation_predictions(train_data, predictions_valid):\n",
    "    pv = []\n",
    "    for i in range(len(train_data)):\n",
    "        pv.append(predictions_valid[i])\n",
    "    return pv\n",
    "\n",
    "def run_cross_validation_create_models(nfolds, X_train, X_test, y_train):\n",
    "    # input image dimensions\n",
    "    batch_size = 8\n",
    "    nb_epoch = 12\n",
    "    random_state = 51\n",
    "\n",
    "    train_data = X_train\n",
    "    train_target = y_train\n",
    "\n",
    "    yfull_train = dict()\n",
    "    kf = KFold(len(y_train), n_folds=nfolds, shuffle=True, random_state=random_state)\n",
    "    num_fold = 0\n",
    "    sum_score = 0\n",
    "    accuracies = 0\n",
    "    models = []\n",
    "    for train_index, test_index in kf:\n",
    "        model = covNetSimple()\n",
    "        X_train = train_data[train_index]\n",
    "        Y_train = train_target[train_index]\n",
    "        X_valid = train_data[test_index]\n",
    "        Y_valid = train_target[test_index]\n",
    "\n",
    "        num_fold += 1\n",
    "        print('Start KFold number {} from {}'.format(num_fold, nfolds))\n",
    "        print('Split train: ', len(X_train), len(Y_train))\n",
    "        print('Split valid: ', len(X_valid), len(Y_valid))\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=5, verbose=0),\n",
    "        ]\n",
    "        \n",
    "        m = len(Y_train)\n",
    "        uniques, frequencies = np.unique(Y_train, return_counts=True)\n",
    "        weights = {0:(m/frequencies[0]), 1:(m/frequencies[1]), 2:(m/frequencies[2]), 3:(m/frequencies[3])}\n",
    "        \n",
    "        model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, class_weight=None, shuffle=True, verbose=2, validation_data=(X_valid, Y_valid), callbacks=callbacks)\n",
    "\n",
    "        predictions_valid = model.predict(X_valid.astype('float32'), batch_size=batch_size, verbose=2)\n",
    "        score = log_loss(Y_valid, predictions_valid)\n",
    "        print('Score log_loss: ', score)\n",
    "        sum_score += score*len(test_index)\n",
    "\n",
    "        # Store valid predictions\n",
    "        for i in range(len(test_index)):\n",
    "            yfull_train[test_index[i]] = predictions_valid[i]\n",
    "\n",
    "        test_prediction = model.predict(X_valid.astype('float32'), batch_size=batch_size, verbose=2)\n",
    "        y_pred = np.zeros([test_prediction.shape[0]])\n",
    "        for i in xrange(test_prediction.shape[0]):\n",
    "            y_pred[i] = np.argmax(test_prediction[i,:]).astype(int)\n",
    "        class_names = [\"0\", \"1\", \"2\", \"3\"]\n",
    "        plotNiceConfusionMatrix(Y_valid.astype(int), y_pred.astype(int), class_names)\n",
    "        scores = model.evaluate(X_valid.astype('float32'), Y_valid, verbose=0)\n",
    "        print y_pred.shape\n",
    "        print Y_valid.shape\n",
    "        acc = accuracy(Y_valid.astype(int), y_pred.astype(int))\n",
    "        print \"Accuracy is: \", acc\n",
    "        \n",
    "        accuracies += acc\n",
    "\n",
    "\n",
    "        models.append(model)\n",
    "\n",
    "    score = sum_score/len(train_data)\n",
    "    print(\"Log_loss train independent avg: \", score)\n",
    "\n",
    "    print \"no accuracy evaluation!\"\n",
    "    final_accuracy = accuracies / nfolds\n",
    "    print \"Accuracy train independent avg in percent: \", final_accuracy\n",
    "\n",
    "    info_string = 'loss_' + str(score) + '_folds_' + str(nfolds) + '_ep_' + str(nb_epoch)\n",
    "    return info_string, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_test_with_cross_val(info_string, models, X_test):\n",
    "    batch_size = 16\n",
    "    num_fold = 0\n",
    "    yfull_test = []\n",
    "    test_id = []\n",
    "    nfolds = len(models)\n",
    "\n",
    "    for i in range(nfolds):\n",
    "        model = models[i]\n",
    "        num_fold += 1\n",
    "        print('Start KFold number {} from {}'.format(num_fold, nfolds))\n",
    "        test_data = X_test\n",
    "        test_prediction = model.predict(test_data, batch_size=batch_size, verbose=2)\n",
    "        yfull_test.append(test_prediction)\n",
    "\n",
    "    test_res = merge_several_folds_mean(yfull_test, nfolds)\n",
    "    info_string = 'loss_' + info_string \\\n",
    "                + '_folds_' + str(nfolds)\n",
    "\n",
    "    print \"Result on test data done: \", test_res.shape\n",
    "    return test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with num_folds =  4\n",
      "Start KFold number 1 from 4\n",
      "('Split train: ', 18143, 18143)\n",
      "('Split valid: ', 6048, 6048)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: expected convolution2d_input_3 to have shape (None, 80, 80, 4) but got array with shape (18143, 40, 40, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8334d02dc4e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Training model with num_folds = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_folds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minfo_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_cross_validation_create_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"done\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-7fa4860c867f>\u001b[0m in \u001b[0;36mrun_cross_validation_create_models\u001b[0;34m(nfolds, X_train, X_test, y_train)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfrequencies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfrequencies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfrequencies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfrequencies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mpredictions_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/moritzberthold/anaconda2/envs/tensorflow/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Users/moritzberthold/anaconda2/envs/tensorflow/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1066\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0mcheck_batch_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1069\u001b[0m         \u001b[0;31m# prepare validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/moritzberthold/anaconda2/envs/tensorflow/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_dim, batch_size)\u001b[0m\n\u001b[1;32m    979\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m                                    \u001b[0mcheck_batch_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m                                    exception_prefix='model input')\n\u001b[0m\u001b[1;32m    982\u001b[0m         y = standardize_input_data(y, self.output_names,\n\u001b[1;32m    983\u001b[0m                                    \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/moritzberthold/anaconda2/envs/tensorflow/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_dim, exception_prefix)\u001b[0m\n\u001b[1;32m    111\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: expected convolution2d_input_3 to have shape (None, 80, 80, 4) but got array with shape (18143, 40, 40, 4)"
     ]
    }
   ],
   "source": [
    "num_folds = 4\n",
    "print \"Training model with num_folds = \", num_folds\n",
    "info_string, models = run_cross_validation_create_models(num_folds, X_train, X_test, y_train)\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"-------------------------------------\"\n",
    "print \"Evaluation on test data:\"\n",
    "prediction = process_test_with_cross_val(info_string, models, X_test)\n",
    "y_pred = np.argmax(prediction, axis=1)\n",
    "print \"The final accuracy on test data is \" + str(accuracy(y_pred, y_test)) + \"%.\"\n",
    "class_names = [\"0\", \"1\", \"2\", \"3\"]\n",
    "plotNiceConfusionMatrix(y_test, y_pred, class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
